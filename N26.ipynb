{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLtUuNczt9gCCidonv+xW0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jakelinecs/Tareas-Machine-Learning/blob/main/N26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jp6ixushGHIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe746f5-b6fa-4c2d-ce29-0f765fa3e0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3-class classification (Iris) training started ---\n",
            "Epoch 001, loss : 17.1048, val_loss : 145.4677, val_acc : 0.500\n",
            "Epoch 002, loss : 13.6411, val_loss : 118.4701, val_acc : 0.708\n",
            "Epoch 003, loss : 10.3908, val_loss : 87.9416, val_acc : 0.583\n",
            "Epoch 004, loss : 7.1911, val_loss : 59.1567, val_acc : 0.708\n",
            "Epoch 005, loss : 3.8212, val_loss : 27.8530, val_acc : 0.667\n",
            "Epoch 006, loss : 0.9779, val_loss : 10.3551, val_acc : 0.292\n",
            "Epoch 007, loss : 0.6544, val_loss : 7.4630, val_acc : 0.625\n",
            "Epoch 008, loss : 0.4310, val_loss : 7.6317, val_acc : 0.667\n",
            "Epoch 009, loss : 0.2822, val_loss : 4.9857, val_acc : 0.542\n",
            "Epoch 010, loss : 0.2453, val_loss : 6.3684, val_acc : 0.667\n",
            "Epoch 011, loss : 0.1873, val_loss : 4.6357, val_acc : 0.625\n",
            "Epoch 012, loss : 0.1830, val_loss : 4.6036, val_acc : 0.625\n",
            "Epoch 013, loss : 0.1638, val_loss : 3.9203, val_acc : 0.625\n",
            "Epoch 014, loss : 0.1548, val_loss : 3.6022, val_acc : 0.667\n",
            "Epoch 015, loss : 0.1364, val_loss : 3.0378, val_acc : 0.708\n",
            "Epoch 016, loss : 0.1178, val_loss : 2.5614, val_acc : 0.750\n",
            "Epoch 017, loss : 0.1042, val_loss : 2.1836, val_acc : 0.750\n",
            "Epoch 018, loss : 0.0919, val_loss : 1.9041, val_acc : 0.750\n",
            "Epoch 019, loss : 0.0809, val_loss : 1.6522, val_acc : 0.792\n",
            "Epoch 020, loss : 0.0737, val_loss : 1.5051, val_acc : 0.833\n",
            "Epoch 021, loss : 0.0665, val_loss : 1.3998, val_acc : 0.833\n",
            "Epoch 022, loss : 0.0613, val_loss : 1.3190, val_acc : 0.833\n",
            "Epoch 023, loss : 0.0571, val_loss : 1.2836, val_acc : 0.875\n",
            "Epoch 024, loss : 0.0535, val_loss : 1.2456, val_acc : 0.875\n",
            "Epoch 025, loss : 0.0505, val_loss : 1.2304, val_acc : 0.875\n",
            "Epoch 026, loss : 0.0475, val_loss : 1.2045, val_acc : 0.875\n",
            "Epoch 027, loss : 0.0455, val_loss : 1.2003, val_acc : 0.875\n",
            "Epoch 028, loss : 0.0429, val_loss : 1.1914, val_acc : 0.875\n",
            "Epoch 029, loss : 0.0407, val_loss : 1.1737, val_acc : 0.875\n",
            "Epoch 030, loss : 0.0393, val_loss : 1.1705, val_acc : 0.875\n",
            "Epoch 031, loss : 0.0374, val_loss : 1.1561, val_acc : 0.875\n",
            "Epoch 032, loss : 0.0363, val_loss : 1.1523, val_acc : 0.875\n",
            "Epoch 033, loss : 0.0349, val_loss : 1.1438, val_acc : 0.875\n",
            "Epoch 034, loss : 0.0336, val_loss : 1.1194, val_acc : 0.875\n",
            "Epoch 035, loss : 0.0332, val_loss : 1.1191, val_acc : 0.875\n",
            "Epoch 036, loss : 0.0316, val_loss : 1.0819, val_acc : 0.875\n",
            "Epoch 037, loss : 0.0319, val_loss : 1.0978, val_acc : 0.875\n",
            "Epoch 038, loss : 0.0296, val_loss : 1.0337, val_acc : 0.875\n",
            "Epoch 039, loss : 0.0314, val_loss : 1.0947, val_acc : 0.917\n",
            "Epoch 040, loss : 0.0271, val_loss : 0.9720, val_acc : 0.875\n",
            "Epoch 041, loss : 0.0320, val_loss : 1.1236, val_acc : 0.917\n",
            "Epoch 042, loss : 0.0238, val_loss : 0.9031, val_acc : 0.875\n",
            "Epoch 043, loss : 0.0346, val_loss : 1.1774, val_acc : 0.917\n",
            "Epoch 044, loss : 0.0210, val_loss : 0.8707, val_acc : 0.833\n",
            "Epoch 045, loss : 0.0369, val_loss : 1.2400, val_acc : 0.917\n",
            "Epoch 046, loss : 0.0189, val_loss : 0.8705, val_acc : 0.833\n",
            "Epoch 047, loss : 0.0380, val_loss : 1.2791, val_acc : 0.917\n",
            "Epoch 048, loss : 0.0172, val_loss : 0.8733, val_acc : 0.792\n",
            "Epoch 049, loss : 0.0371, val_loss : 1.2707, val_acc : 0.917\n",
            "Epoch 050, loss : 0.0160, val_loss : 0.8744, val_acc : 0.792\n",
            "Epoch 051, loss : 0.0356, val_loss : 1.2481, val_acc : 0.917\n",
            "Epoch 052, loss : 0.0152, val_loss : 0.8620, val_acc : 0.792\n",
            "Epoch 053, loss : 0.0333, val_loss : 1.2148, val_acc : 0.917\n",
            "Epoch 054, loss : 0.0143, val_loss : 0.8557, val_acc : 0.833\n",
            "Epoch 055, loss : 0.0317, val_loss : 1.1856, val_acc : 0.917\n",
            "Epoch 056, loss : 0.0136, val_loss : 0.8432, val_acc : 0.833\n",
            "Epoch 057, loss : 0.0298, val_loss : 1.1585, val_acc : 0.917\n",
            "Epoch 058, loss : 0.0130, val_loss : 0.8263, val_acc : 0.833\n",
            "Epoch 059, loss : 0.0280, val_loss : 1.1320, val_acc : 0.917\n",
            "Epoch 060, loss : 0.0124, val_loss : 0.8035, val_acc : 0.833\n",
            "Epoch 061, loss : 0.0263, val_loss : 1.0967, val_acc : 0.917\n",
            "Epoch 062, loss : 0.0121, val_loss : 0.7834, val_acc : 0.833\n",
            "Epoch 063, loss : 0.0248, val_loss : 1.0710, val_acc : 0.917\n",
            "Epoch 064, loss : 0.0117, val_loss : 0.7623, val_acc : 0.833\n",
            "Epoch 065, loss : 0.0231, val_loss : 1.0456, val_acc : 0.917\n",
            "Epoch 066, loss : 0.0112, val_loss : 0.7520, val_acc : 0.833\n",
            "Epoch 067, loss : 0.0219, val_loss : 1.0213, val_acc : 0.917\n",
            "Epoch 068, loss : 0.0107, val_loss : 0.7372, val_acc : 0.833\n",
            "Epoch 069, loss : 0.0204, val_loss : 1.0001, val_acc : 0.917\n",
            "Epoch 070, loss : 0.0103, val_loss : 0.7164, val_acc : 0.833\n",
            "Epoch 071, loss : 0.0183, val_loss : 0.9549, val_acc : 0.917\n",
            "Epoch 072, loss : 0.0102, val_loss : 0.6826, val_acc : 0.833\n",
            "Epoch 073, loss : 0.0165, val_loss : 0.9003, val_acc : 0.917\n",
            "Epoch 074, loss : 0.0104, val_loss : 0.6624, val_acc : 0.875\n",
            "Epoch 075, loss : 0.0144, val_loss : 0.7664, val_acc : 0.917\n",
            "Epoch 076, loss : 0.0116, val_loss : 0.7116, val_acc : 0.917\n",
            "Epoch 077, loss : 0.0118, val_loss : 0.6924, val_acc : 0.917\n",
            "Epoch 078, loss : 0.0119, val_loss : 0.7129, val_acc : 0.917\n",
            "Epoch 079, loss : 0.0113, val_loss : 0.6910, val_acc : 0.917\n",
            "Epoch 080, loss : 0.0112, val_loss : 0.6886, val_acc : 0.917\n",
            "Epoch 081, loss : 0.0110, val_loss : 0.6884, val_acc : 0.917\n",
            "Epoch 082, loss : 0.0107, val_loss : 0.6797, val_acc : 0.917\n",
            "Epoch 083, loss : 0.0105, val_loss : 0.6710, val_acc : 0.917\n",
            "Epoch 084, loss : 0.0103, val_loss : 0.6846, val_acc : 0.917\n",
            "Epoch 085, loss : 0.0097, val_loss : 0.6586, val_acc : 0.917\n",
            "Epoch 086, loss : 0.0098, val_loss : 0.6514, val_acc : 0.917\n",
            "Epoch 087, loss : 0.0096, val_loss : 0.6573, val_acc : 0.917\n",
            "Epoch 088, loss : 0.0091, val_loss : 0.6396, val_acc : 0.917\n",
            "Epoch 089, loss : 0.0091, val_loss : 0.6374, val_acc : 0.917\n",
            "Epoch 090, loss : 0.0088, val_loss : 0.6315, val_acc : 0.917\n",
            "Epoch 091, loss : 0.0086, val_loss : 0.6274, val_acc : 0.917\n",
            "Epoch 092, loss : 0.0083, val_loss : 0.6244, val_acc : 0.917\n",
            "Epoch 093, loss : 0.0080, val_loss : 0.6167, val_acc : 0.917\n",
            "Epoch 094, loss : 0.0078, val_loss : 0.6128, val_acc : 0.917\n",
            "Epoch 095, loss : 0.0076, val_loss : 0.6092, val_acc : 0.917\n",
            "Epoch 096, loss : 0.0074, val_loss : 0.6069, val_acc : 0.917\n",
            "Epoch 097, loss : 0.0072, val_loss : 0.6044, val_acc : 0.958\n",
            "Epoch 098, loss : 0.0069, val_loss : 0.6001, val_acc : 0.958\n",
            "Epoch 099, loss : 0.0067, val_loss : 0.5975, val_acc : 0.958\n",
            "Epoch 100, loss : 0.0065, val_loss : 0.5957, val_acc : 0.958\n",
            "--- Training completed ---\n",
            "test_acc : 0.967\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TensorFlow neural network implementation for Iris dataset (3-class) multi-class classification\n",
        "Using TensorFlow 1.x API\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.datasets import load_iris\n",
        "import tensorflow as tf\n",
        "\n",
        "# TensorFlow 1.x環境で実行する場合は、tf.compat.v1を使用してレガシーなAPIを使用します\n",
        "try:\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "except:\n",
        "    pass  # Si ya está deshabilitado o no es necesario\n",
        "\n",
        "# データセットの読み込み (Iris dataset from sklearn)\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['Species'] = iris.target_names[iris.target]\n",
        "\n",
        "# 3種類すべての目的変数を使用\n",
        "y_labels = df[\"Species\"]\n",
        "X = df[[\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]]\n",
        "\n",
        "# NumPy 配列に変換\n",
        "X = np.array(X)\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "# ラベルをOne-Hotエンコーディングに変換 (3クラス分類のため)\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y_labels)\n",
        "# yのshapeは (n_samples, 3) となる\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ (元のコードから変更なし)\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        # NumPyの整数型キャストをnp.int32に修正\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int32)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = y.shape[1] # クラス数を3に変更\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input], name=\"X_input\")\n",
        "Y = tf.compat.v1.placeholder(\"float\", [None, n_classes], name=\"Y_labels\") # n_classesを3に変更\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    単純な3層ニューラルネットワーク (最終層の出力サイズをn_classes=3に変更)\n",
        "    \"\"\"\n",
        "    tf.compat.v1.set_random_seed(0)\n",
        "    # 重みとバイアスの宣言\n",
        "    weights = {\n",
        "        'w1': tf.compat.v1.Variable(tf.random.normal([n_input, n_hidden1]), name='W1'),\n",
        "        'w2': tf.compat.v1.Variable(tf.random.normal([n_hidden1, n_hidden2]), name='W2'),\n",
        "        'w3': tf.compat.v1.Variable(tf.random.normal([n_hidden2, n_classes]), name='W3') # 出力ノード数をn_classes=3に変更\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.compat.v1.Variable(tf.random.normal([n_hidden1]), name='b1'),\n",
        "        'b2': tf.compat.v1.Variable(tf.random.normal([n_hidden2]), name='b2'),\n",
        "        'b3': tf.compat.v1.Variable(tf.random.normal([n_classes]), name='b3') # バイアスサイズもn_classes=3に変更\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "# ネットワーク構造の読み込み\n",
        "logits = example_net(X)\n",
        "\n",
        "# 目的関数\n",
        "# ★変更点1: tf.nn.sigmoid_cross_entropy_with_logitsを多クラス用のtf.nn.softmax_cross_entropy_with_logitsに変更\n",
        "# TensorFlow 2.xではsoftmax_cross_entropy_with_logits_v2が廃止され、softmax_cross_entropy_with_logitsを使用\n",
        "# labelsはOne-Hotベクトル、logitsは最終出力層の線形結合値\n",
        "try:\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "except:\n",
        "    # Fallback para versiones más antiguas\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# 推定結果と指標値計算\n",
        "# ★変更点2: 2値分類のtf.signを使った判定を、多クラス用の最大値インデックス比較に変更\n",
        "# tf.argmaxで最大値を持つインデックス（予測クラス）を取得\n",
        "prediction = tf.argmax(logits, 1)\n",
        "# tf.argmaxで最大値を持つインデックス（正解クラス）を取得\n",
        "correct_label = tf.argmax(Y, 1)\n",
        "# 予測クラスと正解クラスが一致しているか比較\n",
        "correct_pred = tf.equal(prediction, correct_label)\n",
        "# 正しい予測の平均を計算して精度とする\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# variableの初期化\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init)\n",
        "    print(\"--- 3-class classification (Iris) training started ---\")\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int32)\n",
        "        total_loss = 0\n",
        "\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            # 訓練オペレーションの実行 (重み更新)\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            # 損失計算\n",
        "            loss = sess.run(loss_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "\n",
        "        total_loss /= X_train.shape[0] # サンプル数で割って平均損失を出す\n",
        "\n",
        "        # 検証データでの損失と精度を計算\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "\n",
        "        print(\"Epoch {:03d}, loss : {:.4f}, val_loss : {:.4f}, val_acc : {:.3f}\".format(\n",
        "            epoch + 1, total_loss, val_loss, val_acc))\n",
        "\n",
        "    # テストデータでの精度を計算\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"--- Training completed ---\")\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cc-BdAKWIBDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}