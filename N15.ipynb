{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmLVXTZ47h0Fnuw+B/Itca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jakelinecs/Tareas-Machine-Learning/blob/main/N15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVVtwoa8u-kP",
        "outputId": "dec9e774-f8c3-42fd-ac2b-422e6b529400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データ最終形状: (250491, 242)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    app_train = pd.read_csv('application_train.csv')\n",
        "    app_test = pd.read_csv('application_test.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ CSVファイルが見つかりません。ファイルを配置してください。\")\n",
        "    app_train = pd.DataFrame()\n",
        "    app_test = pd.DataFrame()\n",
        "    exit()\n",
        "\n",
        "y = app_train['TARGET']\n",
        "train_ids = app_train['SK_ID_CURR']\n",
        "test_ids = app_test['SK_ID_CURR']\n",
        "\n",
        "app_train = app_train.drop(columns=['TARGET'])\n",
        "data = pd.concat([app_train, app_test], ignore_index=True)\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == 'object':\n",
        "        if len(list(data[col].unique())) <= 2:\n",
        "            data[col] = le.fit_transform(data[col].astype(str))\n",
        "\n",
        "data = pd.get_dummies(data)\n",
        "\n",
        "data['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)\n",
        "\n",
        "for col in data.columns:\n",
        "    if data[col].isnull().sum() > 0 and data[col].dtype != 'object':\n",
        "        data[col].fillna(data[col].median(), inplace=True)\n",
        "\n",
        "app_train = data[data['SK_ID_CURR'].isin(train_ids)].copy()\n",
        "app_test = data[data['SK_ID_CURR'].isin(test_ids)].copy()\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = app_train.drop(columns=['SK_ID_CURR']).values\n",
        "X_test = app_test.drop(columns=['SK_ID_CURR']).values\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"訓練データ最終形状: {X_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val, X_val, y_train_val, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "logreg = LogisticRegression(C=0.0001, solver='liblinear', max_iter=1000, random_state=42)\n",
        "\n",
        "logreg.fit(X_train_val, y_train_val)\n",
        "\n",
        "y_pred_proba_val = logreg.predict_proba(X_val)[:, 1]\n",
        "\n",
        "auc_baseline = roc_auc_score(y_val, y_pred_proba_val)\n",
        "\n",
        "print(\"\\n--- ベースラインモデルの検証結果 ---\")\n",
        "print(f\"モデル: ロジスティック回帰\")\n",
        "print(f\"検証データ ROC AUC: {auc_baseline:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Nvoc1CvBoY",
        "outputId": "4e257869-9781-4a03-bfa0-4fc7f3989985"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ベースラインモデルの検証結果 ---\n",
            "モデル: ロジスティック回帰\n",
            "検証データ ROC AUC: 0.6749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba_test = logreg.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "submission_baseline = pd.DataFrame({\n",
        "    'SK_ID_CURR': test_ids,\n",
        "    'TARGET': y_pred_proba_test\n",
        "})\n",
        "\n",
        "submission_baseline.to_csv('submission_baseline.csv', index=False)\n",
        "\n",
        "print(\"\\n✅ ベースラインの提出ファイル (submission_baseline.csv) を作成しました。\")\n",
        "print(\"これをKaggleに提出することで提出フローを確認できます。\")\n",
        "print(submission_baseline.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4x69lcpvBkX",
        "outputId": "eb30a716-e438-497a-c20e-8298c95ce716"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ ベースラインの提出ファイル (submission_baseline.csv) を作成しました。\n",
            "これをKaggleに提出することで提出フローを確認できます。\n",
            "   SK_ID_CURR    TARGET\n",
            "0      100001  0.067481\n",
            "1      100005  0.121575\n",
            "2      100013  0.088444\n",
            "3      100028  0.059376\n",
            "4      100038  0.122836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineer(data_df):\n",
        "    df_fe = data_df.copy()\n",
        "\n",
        "    df_fe['AGE'] = df_fe['DAYS_BIRTH'] / -365.25\n",
        "\n",
        "    df_fe['CREDIT_INCOME_RATIO'] = df_fe['AMT_CREDIT'] / (df_fe['AMT_INCOME_TOTAL'] + 1e-6)\n",
        "\n",
        "    df_fe['EXT_SOURCE_PROD'] = df_fe['EXT_SOURCE_1'] * df_fe['EXT_SOURCE_2'] * df_fe['EXT_SOURCE_3']\n",
        "\n",
        "    df_fe['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)\n",
        "\n",
        "    return df_fe\n",
        "\n",
        "fe_results = {}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "fe_results['P0_Baseline_LogReg'] = {'AUC': auc_baseline, 'Features': '全特徴量 (ベースライン前処理)', 'Model': 'LogisticRegression'}\n",
        "\n",
        "\n",
        "data_fe = feature_engineer(data.copy())\n",
        "\n",
        "data_fe = pd.get_dummies(data_fe)\n",
        "app_train_fe = data_fe[data_fe['SK_ID_CURR'].isin(train_ids)].copy()\n",
        "app_test_fe = data_fe[data_fe['SK_ID_CURR'].isin(test_ids)].copy()\n",
        "\n",
        "for col in app_train_fe.columns:\n",
        "    if app_train_fe[col].isnull().sum() > 0:\n",
        "        median_val = app_train_fe[col].median()\n",
        "        app_train_fe[col].fillna(median_val, inplace=True)\n",
        "        app_test_fe[col].fillna(median_val, inplace=True)\n",
        "\n",
        "all_cols = [col for col in app_train_fe.columns if col not in ['SK_ID_CURR', 'TARGET']]\n",
        "\n",
        "X_fe_1 = app_train_fe[all_cols].values\n",
        "X_test_fe_1 = app_test_fe[all_cols].values\n",
        "X_fe_1_scaled = scaler.fit_transform(X_fe_1)\n",
        "X_test_fe_1_scaled = scaler.transform(X_test_fe_1)\n",
        "\n",
        "X_train_val_1, X_val_1, y_train_val_1, y_val_1 = train_test_split(X_fe_1_scaled, y, test_size=0.1, random_state=42)\n",
        "\n",
        "model_rf_1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\n",
        "model_rf_1.fit(X_train_val_1, y_train_val_1)\n",
        "y_pred_1 = model_rf_1.predict_proba(X_val_1)[:, 1]\n",
        "auc_1 = roc_auc_score(y_val_1, y_pred_1)\n",
        "fe_results['P1_All_FE_RF'] = {'AUC': auc_1, 'Features': '全特徴量 + 3新規特徴量', 'Model': 'RandomForest'}\n",
        "\n",
        "\n",
        "ext_source_cols = [col for col in all_cols if 'EXT_SOURCE' in col or 'CREDIT_INCOME_RATIO' in col or 'EXT_SOURCE_PROD' in col]\n",
        "X_fe_2 = app_train_fe[ext_source_cols].values\n",
        "X_test_fe_2 = app_test_fe[ext_source_cols].values\n",
        "X_fe_2_scaled = scaler.fit_transform(X_fe_2)\n",
        "X_test_fe_2_scaled = scaler.transform(X_test_fe_2)\n",
        "\n",
        "X_train_val_2, X_val_2, y_train_val_2, y_val_2 = train_test_split(X_fe_2_scaled, y, test_size=0.1, random_state=42)\n",
        "\n",
        "model_rf_2 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\n",
        "model_rf_2.fit(X_train_val_2, y_train_val_2)\n",
        "y_pred_2 = model_rf_2.predict_proba(X_val_2)[:, 1]\n",
        "auc_2 = roc_auc_score(y_val_2, y_pred_2)\n",
        "fe_results['P2_EXT_Only_FE_RF'] = {'AUC': auc_2, 'Features': 'EXT_SOURCE, CREDIT_INCOME_RATIOのみ', 'Model': 'RandomForest'}\n",
        "\n",
        "\n",
        "logreg_2 = LogisticRegression(C=0.0001, solver='liblinear', max_iter=1000, random_state=42)\n",
        "logreg_2.fit(X_train_val_1, y_train_val_1) # X_fe_1_scaled を使用\n",
        "y_pred_3 = logreg_2.predict_proba(X_val_1)[:, 1]\n",
        "auc_3 = roc_auc_score(y_val_1, y_pred_3)\n",
        "fe_results['P3_All_FE_LogReg'] = {'AUC': auc_3, 'Features': '全特徴量 + 3新規特徴量', 'Model': 'LogisticRegression'}\n",
        "\n",
        "\n",
        "ext_source_base_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
        "X_fe_4 = app_train[ext_source_base_cols].values\n",
        "X_test_fe_4 = app_test[ext_source_base_cols].values\n",
        "X_fe_4_scaled = scaler.fit_transform(X_fe_4)\n",
        "X_test_fe_4_scaled = scaler.transform(X_test_fe_4)\n",
        "\n",
        "X_train_val_4, X_val_4, y_train_val_4, y_val_4 = train_test_split(X_fe_4_scaled, y, test_size=0.1, random_state=42)\n",
        "\n",
        "model_rf_4 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\n",
        "model_rf_4.fit(X_train_val_4, y_train_val_4)\n",
        "y_pred_4 = model_rf_4.predict_proba(X_val_4)[:, 1]\n",
        "auc_4 = roc_auc_score(y_val_4, y_pred_4)\n",
        "fe_results['P4_EXT_Only_Base_RF'] = {'AUC': auc_4, 'Features': 'EXT_SOURCEのみ (ベースライン)', 'Model': 'RandomForest'}\n",
        "\n",
        "\n",
        "df_fe_results = pd.DataFrame(fe_results).T[['AUC', 'Features', 'Model']].sort_values(by='AUC', ascending=False)\n",
        "print(\"\\n--- 特徴量エンジニアリングとモデルの性能比較（5パターン以上） ---\")\n",
        "print(df_fe_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_tmVPrbvBhY",
        "outputId": "8816cdea-4867-44a0-ab55-07a261d9f08e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 特徴量エンジニアリングとモデルの性能比較（5パターン以上） ---\n",
            "                          AUC                           Features  \\\n",
            "P1_All_FE_RF          0.72416                      全特徴量 + 3新規特徴量   \n",
            "P2_EXT_Only_FE_RF    0.716702  EXT_SOURCE, CREDIT_INCOME_RATIOのみ   \n",
            "P4_EXT_Only_Base_RF  0.714654              EXT_SOURCEのみ (ベースライン)   \n",
            "P3_All_FE_LogReg     0.686181                      全特徴量 + 3新規特徴量   \n",
            "P0_Baseline_LogReg   0.674899                   全特徴量 (ベースライン前処理)   \n",
            "\n",
            "                                  Model  \n",
            "P1_All_FE_RF               RandomForest  \n",
            "P2_EXT_Only_FE_RF          RandomForest  \n",
            "P4_EXT_Only_Base_RF        RandomForest  \n",
            "P3_All_FE_LogReg     LogisticRegression  \n",
            "P0_Baseline_LogReg   LogisticRegression  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model_rf_1\n",
        "X_test_final = X_test_fe_1_scaled\n",
        "\n",
        "y_pred_proba_final = final_model.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "submission_final = pd.DataFrame({\n",
        "    'SK_ID_CURR': test_ids,\n",
        "    'TARGET': y_pred_proba_final\n",
        "})\n",
        "\n",
        "submission_final.to_csv('submission_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- 最終提出ファイル ---\")\n",
        "print(f\"最終モデル: ランダムフォレスト (P1)\")\n",
        "print(f\"最終提出ファイル (submission_final.csv) を作成しました。\")\n",
        "print(submission_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8UwjUe8vBeo",
        "outputId": "1713d3bf-bbb9-4958-c5b2-525bfa19cc23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 最終提出ファイル ---\n",
            "最終モデル: ランダムフォレスト (P1)\n",
            "最終提出ファイル (submission_final.csv) を作成しました。\n",
            "   SK_ID_CURR    TARGET\n",
            "0      100001  0.077532\n",
            "1      100005  0.091831\n",
            "2      100013  0.063223\n",
            "3      100028  0.048404\n",
            "4      100038  0.116927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8aucp-svBbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygHbbhOxvBV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIC2qR8UvBSn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}