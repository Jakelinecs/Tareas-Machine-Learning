{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3pO4UJiiKSN+Xh4GDFhfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jakelinecs/Tareas-Machine-Learning/blob/main/N30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e86e3f99",
        "outputId": "75fc3566-fa0e-4ae5-e97c-b6b5e425a871"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Specify the directory to remove\n",
        "extraction_dir = '/content/train' # Make sure this is the correct directory you want to remove\n",
        "\n",
        "# Check if the directory exists before attempting to remove it\n",
        "if os.path.exists(extraction_dir):\n",
        "    shutil.rmtree(extraction_dir)\n",
        "    print(f\"Directory '{extraction_dir}' and its contents have been removed.\")\n",
        "else:\n",
        "    print(f\"Directory '{extraction_dir}' does not exist.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/train' and its contents have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20cfcd9b",
        "outputId": "e14aae6a-5808-465c-c255-810ba1d6c20b"
      },
      "source": [
        "# Specify the path to your zip file\n",
        "zip_file_path = 'train.zip' # Replace with the actual path to your zip file\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extraction_dir = '/content/train' # You can change this to your desired directory\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_dir, exist_ok=True)\n",
        "\n",
        "# Open the zip file in read mode\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extraction_dir)\n",
        "\n",
        "print(f\"Successfully extracted '{zip_file_path}' to '{extraction_dir}'\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted 'train.zip' to '/content/train'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6eb3529",
        "outputId": "22da74b3-53af-48c0-cd23-f42cf952e482"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "# --- 1. Data preparation settings and generator ---\n",
        "DATA_DIR = './train/'  # Usar dataset del 20% para pruebas rápidas\n",
        "IMG_SIZE_ORIG = 101\n",
        "IMG_SIZE_TARGET = 128\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "class TGSDataGenerator(Sequence):\n",
        "    \"\"\"Keras Data Generator for TGS Salt Challenge\"\"\"\n",
        "    def __init__(self, df, batch_size=16, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        list_IDs_temp = self.df.iloc[indexes]['id'].tolist()\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        return X, y\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        X = np.empty((self.batch_size, IMG_SIZE_TARGET, IMG_SIZE_TARGET, IMG_CHANNELS), dtype=np.float32)\n",
        "        y = np.empty((self.batch_size, IMG_SIZE_TARGET, IMG_SIZE_TARGET, IMG_CHANNELS), dtype=np.float32)\n",
        "\n",
        "        for i, id_name in enumerate(list_IDs_temp):\n",
        "            img_path = os.path.join(DATA_DIR, 'images', id_name + '.png')\n",
        "            mask_path = os.path.join(DATA_DIR, 'masks', id_name + '.png')\n",
        "\n",
        "            try:\n",
        "                img = imread(img_path)\n",
        "                mask = imread(mask_path)\n",
        "            except FileNotFoundError:\n",
        "                # Crear datos dummy si no se encuentra el archivo\n",
        "                img = np.random.randint(0, 255, (IMG_SIZE_TARGET, IMG_SIZE_TARGET), dtype=np.uint8)\n",
        "                mask = np.random.randint(0, 255, (IMG_SIZE_TARGET, IMG_SIZE_TARGET), dtype=np.uint8)\n",
        "\n",
        "            img = img[:, :, 0] if img.ndim == 3 else img\n",
        "            mask = mask[:, :, 0] if mask.ndim == 3 else mask\n",
        "\n",
        "            img_resized = resize(img, (IMG_SIZE_TARGET, IMG_SIZE_TARGET), mode='constant', preserve_range=True)\n",
        "            mask_resized = resize(mask, (IMG_SIZE_TARGET, IMG_SIZE_TARGET), mode='constant', preserve_range=True)\n",
        "\n",
        "            # Normalize images and masks, add channel dimension\n",
        "            X[i,] = (img_resized / 255.0).reshape(IMG_SIZE_TARGET, IMG_SIZE_TARGET, IMG_CHANNELS)\n",
        "            y[i,] = (mask_resized / 255.0).reshape(IMG_SIZE_TARGET, IMG_SIZE_TARGET, IMG_CHANNELS)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def load_tgs_data(data_dir=DATA_DIR, batch_size=16, test_size=0.2, val_size=0.2):\n",
        "    \"\"\"Load dataset and create generators\"\"\"\n",
        "    try:\n",
        "        # Get filenames from the images folder in data_dir\n",
        "        all_files = [f.split('.')[0] for f in os.listdir(os.path.join(data_dir, 'images')) if f.endswith('.png')]\n",
        "        df_ids = pd.DataFrame({'id': all_files})\n",
        "    except FileNotFoundError:\n",
        "        print(\"ERROR: TGS Salt dataset files not found in DATA_DIR. Please check the path.\")\n",
        "        return None, None, None\n",
        "\n",
        "    if len(df_ids) == 0:\n",
        "        print(\"ERROR: Image files not found.\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Data splitting\n",
        "    train_df, temp_df = train_test_split(df_ids, test_size=(test_size + val_size), random_state=42)\n",
        "    val_df, _ = train_test_split(temp_df, test_size=val_size/(test_size + val_size), random_state=42)\n",
        "\n",
        "    print(f\"Total images: {len(df_ids)}, Train: {len(train_df)}, Val: {len(val_df)}\")\n",
        "\n",
        "    train_gen = TGSDataGenerator(train_df, batch_size=batch_size, shuffle=True)\n",
        "    val_gen = TGSDataGenerator(val_df, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_gen, val_gen\n",
        "\n",
        "# --- 2. U-Net Decoder Blocks ---\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "    \"\"\"Double Conv layers and BN layers for U-Net decoder\"\"\"\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# --- 3. Encoder Definition (Transfer Learning) ---\n",
        "def convert_to_3channel(input_tensor):\n",
        "    return Conv2D(3, (1, 1), padding='same', name='input_3ch_conversion')(input_tensor)\n",
        "\n",
        "def get_resnet_encoder(input_tensor, trainable_encoder=False):\n",
        "    \"\"\"Use ResNet50 as encoder\"\"\"\n",
        "    input_3_channel = convert_to_3channel(input_tensor)\n",
        "\n",
        "    base_model = ResNet50(weights='imagenet',\n",
        "                          include_top=False,\n",
        "                          input_shape=(IMG_SIZE_TARGET, IMG_SIZE_TARGET, 3))\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = trainable_encoder\n",
        "\n",
        "    x = base_model(input_3_channel)\n",
        "    bottom_output = x\n",
        "    skip_layers = []\n",
        "\n",
        "    return bottom_output, skip_layers, bottom_output\n",
        "\n",
        "def get_vgg_encoder(input_tensor, trainable_encoder=False):\n",
        "    \"\"\"Use VGG16 as encoder\"\"\"\n",
        "    input_3_channel = convert_to_3channel(input_tensor)\n",
        "\n",
        "    base_model = VGG16(weights='imagenet',\n",
        "                       include_top=False,\n",
        "                       input_shape=(IMG_SIZE_TARGET, IMG_SIZE_TARGET, 3))\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = trainable_encoder\n",
        "\n",
        "    x = base_model(input_3_channel)\n",
        "    bottom_output = x\n",
        "    skip_layers = []\n",
        "\n",
        "    return bottom_output, skip_layers, bottom_output\n",
        "\n",
        "# --- 4. U-Net Model Building Function ---\n",
        "\n",
        "def build_transfer_unet(encoder_name='VGG16', trainable_encoder=False):\n",
        "    \"\"\"Build a U-Net model with the specified encoder\"\"\"\n",
        "    input_shape = (IMG_SIZE_TARGET, IMG_SIZE_TARGET, IMG_CHANNELS)\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # 1. Encoder selection and construction\n",
        "    if encoder_name == 'VGG16':\n",
        "        bottom_output, skip_layers, lowest_skip = get_vgg_encoder(inputs, trainable_encoder)\n",
        "    elif encoder_name == 'ResNet50':\n",
        "        bottom_output, skip_layers, lowest_skip = get_resnet_encoder(inputs, trainable_encoder)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown encoder: {encoder_name}\")\n",
        "\n",
        "    # 2. Bottleneck layer\n",
        "    x = conv_block(bottom_output, 512)\n",
        "\n",
        "    # 3. Decoder construction - Both encoders should output 4x4 for IMG_SIZE_TARGET x IMG_SIZE_TARGET input\n",
        "    # 4x4 -> 8x8\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = conv_block(x, 256)\n",
        "\n",
        "    # 8x8 -> 16x16\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = conv_block(x, 128)\n",
        "\n",
        "    # 16x16 -> 32x32\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = conv_block(x, 64)\n",
        "\n",
        "    # 32x32 -> 64x64\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = conv_block(x, 32)\n",
        "\n",
        "    # 64x64 -> 128x128\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = conv_block(x, 16)\n",
        "\n",
        "    # 4. Final output layer\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "    output = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output, name=f\"U-Net_{encoder_name}\")\n",
        "    return model\n",
        "\n",
        "# --- 5. IoU Metric and Main Execution Block ---\n",
        "\n",
        "def mean_iou(y_true, y_pred):\n",
        "    \"\"\"Keras compatible Mean IoU metric\"\"\"\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    y_pred_f = tf.cast(y_pred_f > 0.5, tf.float32)\n",
        "\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
        "\n",
        "    epsilon = tf.keras.backend.epsilon()\n",
        "    union = tf.maximum(union, epsilon)\n",
        "\n",
        "    iou = intersection / union\n",
        "    return iou\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 3\n",
        "\n",
        "    # 1. Load data generators\n",
        "    train_gen, val_gen = load_tgs_data(batch_size=BATCH_SIZE)\n",
        "\n",
        "    if train_gen is None:\n",
        "        print(\"Skipping execution. Please check if the data is correctly placed.\")\n",
        "    else:\n",
        "        # --- ResNet50 Model Training and Evaluation ---\n",
        "        print(\"\\n--- Training ResNet50 Encoder U-Net ---\")\n",
        "        resnet_model = build_transfer_unet(encoder_name='ResNet50', trainable_encoder=False)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
        "        resnet_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[mean_iou])\n",
        "\n",
        "        print(f\"ResNet50: Running training for {EPOCHS} epochs...\")\n",
        "        resnet_history = resnet_model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            steps_per_epoch=len(train_gen),\n",
        "            epochs=EPOCHS,\n",
        "            verbose=1\n",
        "        )\n",
        "        resnet_iou = resnet_history.history['val_mean_iou'][-1]\n",
        "        print(f\"ResNet50 IoU (Final Val): {resnet_iou:.4f}\")\n",
        "\n",
        "        # --- VGG16 Model Training and Evaluation ---\n",
        "        print(\"\\n--- Training VGG16 Encoder U-Net ---\")\n",
        "        vgg_model = build_transfer_unet(encoder_name='VGG16', trainable_encoder=False)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
        "        vgg_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[mean_iou])\n",
        "\n",
        "        print(f\"VGG16: Running training for {EPOCHS} epochs...\")\n",
        "        vgg_history = vgg_model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            steps_per_epoch=len(train_gen),\n",
        "            epochs=EPOCHS,\n",
        "            verbose=1\n",
        "        )\n",
        "        vgg_iou = vgg_history.history['val_mean_iou'][-1]\n",
        "        print(f\"VGG16 IoU (Final Val): {vgg_iou:.4f}\")\n",
        "\n",
        "        # --- Result Comparison ---\n",
        "        print(\"\\n--- Comparison Results ---\")\n",
        "        print(f\"ResNet50 Final Validation IoU: {resnet_iou:.4f}\")\n",
        "        print(f\"VGG16 Final Validation IoU: {vgg_iou:.4f}\")\n",
        "\n",
        "        if resnet_iou > vgg_iou:\n",
        "            print(\"=> ResNet50 showed higher accuracy with this initial setting.\")\n",
        "        elif vgg_iou > resnet_iou:\n",
        "            print(\"=> VGG16 showed higher accuracy with this initial setting.\")\n",
        "        else:\n",
        "            print(\"=> No significant difference in accuracy was observed.\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "Total images: 800, Train: 480, Val: 160\n",
            "\n",
            "--- Training ResNet50 Encoder U-Net ---\n",
            "ResNet50: Running training for 3 epochs...\n",
            "Epoch 1/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7s/step - loss: 12.1993 - mean_iou: 1.5916 - val_loss: 9.5455 - val_mean_iou: 0.9823\n",
            "Epoch 2/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 7s/step - loss: -39.5019 - mean_iou: 10.0373 - val_loss: -26.2061 - val_mean_iou: 8.9623\n",
            "Epoch 3/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 7s/step - loss: -76.3075 - mean_iou: 39.2950 - val_loss: -76.9791 - val_mean_iou: 41.5194\n",
            "ResNet50 IoU (Final Val): 41.5194\n",
            "\n",
            "--- Training VGG16 Encoder U-Net ---\n",
            "VGG16: Running training for 3 epochs...\n",
            "Epoch 1/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 11s/step - loss: -13.3027 - mean_iou: 2.2141 - val_loss: -56.4645 - val_mean_iou: 4.3941\n",
            "Epoch 2/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 11s/step - loss: -156.7235 - mean_iou: 17.1759 - val_loss: -162.5457 - val_mean_iou: 7.4563\n",
            "Epoch 3/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 11s/step - loss: -278.4838 - mean_iou: 37.7963 - val_loss: -342.0074 - val_mean_iou: 31.7776\n",
            "VGG16 IoU (Final Val): 31.7776\n",
            "\n",
            "--- Comparison Results ---\n",
            "ResNet50 Final Validation IoU: 41.5194\n",
            "VGG16 Final Validation IoU: 31.7776\n",
            "=> ResNet50 showed higher accuracy with this initial setting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTjVpGlcBrOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}